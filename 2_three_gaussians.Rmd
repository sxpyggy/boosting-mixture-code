---
title: "Gaussian Mixture Boosting"
author: "Hou, Li, Gao"
date: "2023/7/16"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Negative log-likelihood

```{r}
rm(list=ls())
library(xgboost)
source("0_multiclass_bst.R")
source("0_gaussian_bst.R")
draw_figure=F
parallel=T

cores <- detectCores(logical = FALSE)
c1 <- makeCluster(cores)
clusterEvalQ(c1,library(rpart))
clusterEvalQ(c1,library(partykit))
ylim_5<-c(2.39,2.7)
ylim_3<-c(2.39,2.7)
```

# Data genaration

```{r data generation}
n = 10000
ntest = 2000
dat<-sim_gaussian(n,seed=1)
dat_test<-sim_gaussian(ntest,seed=7)
dat_test$true_mu<-dat_test$P1*dat_test$MU1 + dat_test$P2*dat_test$MU2 + dat_test$P3*dat_test$MU3
true_test_mse<-mean((dat_test$true_mu-dat_test$Y)^2)

names(dat)

if (draw_figure==T) png("./plots/three_gaussians/boxplot_p.png")
boxplot(dat[,c("P1","P2","P3")],main="boxplot of mixing probabilities")
if (draw_figure==T) dev.off()

boxplot(dat_test[,c("P1","P2","P3")])
boxplot(dat[,c("Y1","Y2","Y3")])
boxplot(dat_test[,c("Y1","Y2","Y3")])

if (draw_figure==T) png("./plots/three_gaussians/histogram.png")
plot(density(dat$Y,width = 2),main="histogram of Y",xlab="Y",lwd=1.5)
abline(v=c(-5,0,5),lty=2)
if (draw_figure==T) dev.off()

dtest<-xgb.DMatrix(as.matrix(dat_test[,c("X1","X2","X3","X4","X5","X6")]))
```

# Null model 

```{r}
ylim0<-c(2.46,2.75)
X<-dat[, c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y
Xtest<-dat_test[, c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-50
model<-"null"
structure<-"null"
trace<-T
patience<-2
time_temp<-proc.time()
model_homo3<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace, patience=patience)
(time_null<-proc.time()-time_temp)

if (draw_figure==T) png("./plots/three_gaussians/loss-null.png")
matplot(cbind(model_homo3$learn_loss,model_homo3$test_loss), lty = c(1,1) ,col=c('red',"blue"),ylim=ylim0,xlab = "iterations of EM",ylab="neg LL",type="l", main="EM algorithm for null model")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_homo3$learn_loss),lty=2,col="red")
abline(v=which.min(model_homo3$test_loss),lty=2,col="blue")
if (draw_figure==T) dev.off()
homo_learn_loss3 <- model_homo3$learn_loss[length(model_homo3$learn_loss)]
(homo_test_loss3 <- model_homo3$test_loss[length(model_homo3$test_loss)])
(true_test_loss3<-neg_ll3(dat_test$Y,dat_test[,c("MU1","MU2","MU3")],dat_test[,c("SG1","SG2","SG3")], dat_test[,c("P1","P2","P3")]))

(M3<-unique(model_homo3$fitted$mu1))
(M2<-unique(model_homo3$fitted$mu2))
(M1<-unique(model_homo3$fitted$mu3))

dat_test$null_mu3<-
  model_homo3$test$mu1*model_homo3$test$p1+
  model_homo3$test$mu2*model_homo3$test$p2+
  model_homo3$test$mu3*model_homo3$test$p3
unique(dat_test$null_mu3)
unique(dat_test$null_mu5)

(homo_test_mse3<-mean((dat_test$Y-dat_test$null_mu3)^2))
```

# Boosting both

## Iterations

```{r}
X<-dat[1:8000,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y[1:8000]
Xval<-dat[8001:10000,c("X1","X2","X3","X4","X5","X6")]
Yval<-dat$Y[8001:10000]
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-10
structure<-"both"
trace<-T

time_temp<-Sys.time()
time_temp2<-proc.time()
model_bst_both3<-EB_gaussian(X=X, Y=Y, Xval=Xval, Yval=Yval, M0=M0,  n_tree_mu=100, n_tree_p=100, structure=structure, trace=trace, patience = 2, parallel = parallel,
                             int_mu1=M1,int_mu2=M2,int_mu3=M3)
(time_b<-difftime(Sys.time(),time_temp))
(time_b2<-proc.time()-time_temp2)
if(parallel==T){
  bst_time_parallel3=ifelse(as.numeric(time_b)*60>3000,as.numeric(time_b),as.numeric(time_b)*60)
}
if(parallel==F){
  bst_time_no_parallel3=as.numeric(time_b)*60
}

setinfo(dtest, "base_margin", rep(M1,nrow(dat_test)))
dat_test$mu1<-predict(model_bst_both3$mu_models[[1]],newdata = dtest)
setinfo(dtest, "base_margin", rep(M2,nrow(dat_test)))
dat_test$mu2<-predict(model_bst_both3$mu_models[[2]],newdata = dtest)
setinfo(dtest, "base_margin", rep(M3,nrow(dat_test)))
dat_test$mu3<-predict(model_bst_both3$mu_models[[3]],newdata = dtest)
dat_test$sigma1<-unique(model_bst_both3$sigma[1])
dat_test$sigma2<-unique(model_bst_both3$sigma[2])
dat_test$sigma3<-unique(model_bst_both3$sigma[3])
dat_test[,c("p1","p2","p3")]<-predict_BST(Xtest, model_bst_both3$p_model, Pinit=NULL, M_best = which.min(model_bst_both3$p_model$Valid_loss), type="response")

(bst_test_loss_both3 <- neg_ll3(dat_test$Y, dat_test[, c("mu1", "mu2", "mu3")], dat_test[, c("sigma1", "sigma2", "sigma3")], dat_test[, c("p1", "p2", "p3")]))
homo_test_loss3
dat_test$bst3<-dat_test$mu1*dat_test$p1+dat_test$mu2*dat_test$p2+dat_test$mu3*dat_test$p3
(bst_test_mse_both3<-mean((dat_test$Y-dat_test$bst3)^2))
homo_test_mse3
```

## trace plot of loss
```{r}
mu1_int_train<-weighted.mean((Y-M1)^2,w=model_bst_both3$fitted$weight1)^0.5
mu1_int_valid<-weighted.mean((Yval-M1)^2,w=model_bst_both3$valid$weight1)^0.5
trace_mu1_loss<-rbind(t(c(mu1_int_train,mu1_int_valid)),as.matrix(model_bst_both3$mu_models[[1]]$evaluation_log[,2:3]))

mu2_int_train<-weighted.mean((Y-M2)^2,w=model_bst_both3$fitted$weight2)^0.5
mu2_int_valid<-weighted.mean((Yval-M2)^2,w=model_bst_both3$valid$weight2)^0.5
trace_mu2_loss<-rbind(t(c(mu2_int_train,mu2_int_valid)),as.matrix(model_bst_both3$mu_models[[2]]$evaluation_log[,2:3]))

mu3_int_train<-weighted.mean((Y-M3)^2,w=model_bst_both3$fitted$weight3)^0.5
mu3_int_valid<-weighted.mean((Yval-M3)^2,w=model_bst_both3$valid$weight3)^0.5
trace_mu3_loss<-rbind(t(c(mu3_int_train,mu3_int_valid)),as.matrix(model_bst_both3$mu_models[[3]]$evaluation_log[,2:3]))

if (draw_figure==T)  png("./plots/three_gaussians/3-both-mu1-loss.png")
matplot(0:(nrow(trace_mu1_loss)-1),trace_mu1_loss,
        type="l",xlab = "boosting iterations", ylab="loss", col=c("blue","red"), lty=1:2, lwd=1.5,main="mu1")
legend("topright",c("training loss","validation loss"),col=c("blue","red"),lty=1:2,lwd=1.5)
abline(v=which.min(trace_mu1_loss[,2])-1,lty=2,col="red")
if (draw_figure==T) dev.off()

if (draw_figure==T)  png("./plots/three_gaussians/3-both-mu2-loss.png")
matplot(0:(nrow(trace_mu2_loss)-1),trace_mu2_loss,
        type="l",xlab = "boosting iterations", ylab="loss", col=c("blue","red"), lty=1:2, lwd=1.5,main="mu2")
legend("topright",c("training loss","validation loss"),col=c("blue","red"),lty=1:2,lwd=1.5)
abline(v=which.min(trace_mu2_loss[,2])-1,lty=2,col="red")
if (draw_figure==T) dev.off()

if (draw_figure==T)  png("./plots/three_gaussians/3-both-mu3-loss.png")
matplot(0:(nrow(trace_mu3_loss)-1),trace_mu3_loss,
        type="l",xlab = "boosting iterations", ylab="loss", col=c("blue","red"), lty=1:2, lwd=1.5, main="mu3")
legend("topright",c("training loss","validation loss"),col=c("blue","red"),lty=1:2,lwd=1.5)
abline(v=which.min(trace_mu3_loss[,2])-1,lty=2,col="red")
if (draw_figure==T) dev.off()

if (draw_figure==T)  png("./plots/three_gaussians/3-both-probs-loss.png")
matplot(1:length(model_bst_both3$p_model$Train_loss), cbind(model_bst_both3$p_model$Train_loss, model_bst_both3$p_model$Valid_loss),
        type="l",xlab = "boosting iterations", ylab="loss", col=c("blue","red"), lty=1:2, lwd=1.5)
legend("topright",c("training loss","validation loss"),col=c("blue","red"),lty=1:2,lwd=1.5)
abline(v=which.min(model_bst_both3$p_model$Valid_loss),lty=2,col="red")
if (draw_figure==T) dev.off()
```

## Variable importance

```{r}
# variable importance in component mean
model_bst_both3$mu_iter
boxplot(cbind(dat_test[ ,c("mu1","mu2","mu3")]))

var_ind<-data.frame(var_name=c("X1","X2","X3","X4","X5","X6"),ind=1:6)
mu_importance3<-data.frame(var_name=var_ind$var_name[order(var_ind$ind)],mu1=NA,mu2=NA,mu3=NA)
tree_importance3<-NULL

for (k in 1:3){
  boost_model<-model_bst_both3$mu_models[[k]]
  tree_bst<-xgb.model.dt.tree(model = boost_model)
  gain_mat<-aggregate(Quality ~ Feature, data=tree_bst,FUN=sum)
  gain_mat<-gain_mat[-which(gain_mat$Feature=="Leaf"),]
  gain_mat<-merge(var_ind,gain_mat,by.x="var_name",by.y="Feature",all.x=T)
  gain_mat$Quality[which(is.na(gain_mat$Quality)==T)]<-0
  mu_importance3[,k+1]<-gain_mat$Quality[order(gain_mat$ind)]
  
  tree_mat<-aggregate(Quality ~ Tree, data=tree_bst,FUN=sum)
  tree_importance3[[k]]<-tree_mat
}
(mu_importance3$total<-apply(mu_importance3[,-1],1,sum))

tree_imp_mat3<-matrix(0,ncol=3,nrow=max(sapply(tree_importance3,nrow)))
for (k in 1:3){
  tree_imp_mat3[1:length(tree_importance3[[k]]$Quality),k]<-tree_importance3[[k]]$Quality
}

par(mfrow=c(2,2))
for (k in 1:3){
  if (draw_figure==T) png(paste(c("./plots/three_gaussians/3-both-mu-"),k,c(".png"),sep=""))
  barplot(mu_importance3[,k+1], names.arg = mu_importance3$var_name,ylab="relative importance",main=paste("relative importance in mu",k,sep=""),ylim=range(mu_importance3[,-c(1)]))
  box()
  if (draw_figure==T)dev.off()
}

if (draw_figure==T) png("./plots/three_gaussians/3-both-mu-total.png")
barplot(mu_importance3[,5], names.arg = mu_importance3$var_name,ylab="relative importance",main=paste("relative importance in all means"),ylim=range(mu_importance3[,-c(1)]))
box()
if (draw_figure==T) dev.off()

if (draw_figure==T) png("./plots/three_gaussians/3-both-mu-trace.png")
matplot(tree_imp_mat3,type="l",xlab="boosting iterations in the last EB step",ylab="squared loss reduction",col=1:3,lty = 1:3,lwd=1.5)
legend("topright",c("mu1","mu2","mu3"),col=1:3,lty = 1:3,lwd=1.5)
if (draw_figure==T) dev.off()

# variable importance in mixing probabilities
boxplot(dat_test[ ,c("p1", "p2", "p3")])

vi_both3<-array(0,dim=c(K=3,length(model_bst_both3$p_model$Tree_0),6))

for (k in 1:3){
  for (m in 1: length(model_bst_both3$p_model$Tree_0)){
    VI3<-model_bst_both3$p_model$Tree_0[[m]][[k]]$variable.importance

    if (length(VI3)>0){
    for (i in 1:length(VI3)){
      if (names(VI3)[i]=="X1"){
        vi_both3[k,m,1]<-VI3[i]
      }
      if (names(VI3)[i]=="X2"){
        vi_both3[k,m,2]<-VI3[i]
      }
      if (names(VI3)[i]=="X3"){
        vi_both3[k,m,3]<-VI3[i]
      }
      if (names(VI3)[i]=="X4"){
        vi_both3[k,m,4]<-VI3[i]
      }
      if (names(VI3)[i]=="X5"){
        vi_both3[k,m,3]<-VI3[i]
      }
      if (names(VI3)[i]=="X6"){
        vi_both3[k,m,6]<-VI3[i]
      }
    }
    }
  }
}

apply(vi_both3[1,,],2,sum)
apply(vi_both3[2,,],2,sum)
apply(vi_both3[3,,],2,sum)

ylim_bar<-range(cbind(apply(vi_both3[1,,],2,sum),apply(vi_both3[2,,],2,sum),apply(vi_both3[3,,],2,sum)))

par(mfrow=c(2,2))
for (k in 1:3){
  if (draw_figure==T) png(paste(c("./plots/three_gaussians/3-both-prob-"),k,c(".png"),sep=""))
  barplot(apply(vi_both3[k,,],2,sum),names.arg =  c("x1","x2","x3","x4","x5","x6"),ylab="relative importance",main=paste("relative importance in F",k,sep=""),ylim = ylim_bar)
  box()
  if (draw_figure==T) dev.off()
}

if (draw_figure==T)  png("./plots/three_gaussians/3-both-prob-total.png")
barplot(c(sum(vi_both3[,,1]),
sum(vi_both3[,,2]),
sum(vi_both3[,,3]),
sum(vi_both3[,,4]),
sum(vi_both3[,,5]),
sum(vi_both3[,,6])),names.arg =  c("x1","x2","x3","x4","x5","x6"),ylab="relative importance",main="relative importance of covariates")
box()
if (draw_figure==T) dev.off()

vimp_both3<-cbind(apply(vi_both3[1,,],1,sum),apply(vi_both3[2,,],1,sum),apply(vi_both3[3,,],1,sum))

if (draw_figure==T) png("./plots/three_gaussians/3-both-prob-trace.png")
matplot(vimp_both3,type="l",xlab="boosting iterations in the last EB step",ylab="squared loss reduction",col=1:3,lty = 1:3,lwd=1.5)
legend("topright",c("F1","F2","F3"),col=1:3,lty = 1:3,lwd=1.5)
if (draw_figure==T) dev.off()
if (draw_figure==T) {
  write.csv(mu_importance3, "./plots/three_gaussians/3-both-mu-imp.csv")
  write.csv(data.frame(var_name=c("X1","X2","X3","X4","X5","X6"), F1=apply(vi_both3[1,,],2,sum), F2=apply(vi_both3[2,,],2,sum),
F3=apply(vi_both3[3,,],2,sum)),"./plots/three_gaussians/3-both-mix-imp.csv")
  }
```


# Boosting mix

## Iterations

```{r}
X<-dat[1:8000,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y[1:8000]
Xval<-dat[8001:10000,c("X1","X2","X3","X4","X5","X6")]
Yval<-dat$Y[8001:10000]
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-10
structure<-"p"
trace<-T

time_temp<-Sys.time()
time_temp2<-proc.time()
model_bst_both3<-EB_gaussian(X=X, Y=Y, Xval=Xval, Yval=Yval, M0=M0,  n_tree_mu=100, n_tree_p=100, structure=structure, trace=trace, patience = 2, parallel = parallel)
(time_b<-difftime(Sys.time(),time_temp))
(time_b2<-proc.time()-time_temp2)
if(parallel==T){
  bst_mix_time_parallel3=ifelse(as.numeric(time_b)*60>3000,as.numeric(time_b),as.numeric(time_b)*60)
}
if(parallel==F){
  bst_mix_time_no_parallel3=as.numeric(time_b)*60
}

dat_test$mu1<-predict(model_bst_both3$mu_models[[1]],newdata = dat_test)
dat_test$mu2<-predict(model_bst_both3$mu_models[[2]],newdata = dat_test)
dat_test$mu3<-predict(model_bst_both3$mu_models[[3]],newdata = dat_test)
dat_test$sigma1<-unique(model_bst_both3$sigma[1])
dat_test$sigma2<-unique(model_bst_both3$sigma[2])
dat_test$sigma3<-unique(model_bst_both3$sigma[3])
dat_test[,c("p1","p2","p3")]<-predict_BST(Xtest, model_bst_both3$p_model, Pinit=NULL, M_best = which.min(model_bst_both3$p_model$Valid_loss), type="response")

(bst_test_loss_mix3 <- neg_ll3(dat_test$Y, dat_test[, c("mu1", "mu2", "mu3")], dat_test[, c("sigma1", "sigma2", "sigma3")], dat_test[, c("p1", "p2", "p3")]))
bst_test_loss_both3

dat_test$bst_mix3<-dat_test$mu1*dat_test$p1+dat_test$mu2*dat_test$p2+dat_test$mu3*dat_test$p3
(bst_test_mse_mix3<-mean((dat_test$Y-dat_test$bst_mix3)^2))
bst_test_mse_both3
```

## trace plot of loss

```{r}
matplot(1:length(model_bst_both3$p_model$Train_loss), cbind(model_bst_both3$p_model$Train_loss, model_bst_both3$p_model$Valid_loss),
        type="l",xlab = "boosting iterations", ylab="loss", col=c("blue","red"), lty=1:2, lwd=1.5)
legend("topright",c("training loss","validation loss"),col=c("blue","red"),lty=1:2,lwd=1.5)
abline(v=which.min(model_bst_both3$p_model$Valid_loss),lty=2,col="red")
```

## Variable importance

```{r}
vi_both3<-array(0,dim=c(K=3,length(model_bst_both3$p_model$Tree_0),6))

for (k in 1:3){
  for (m in 1: length(model_bst_both3$p_model$Tree_0)){
    VI3<-model_bst_both3$p_model$Tree_0[[m]][[k]]$variable.importance

    if (length(VI3)>0){
    for (i in 1:length(VI3)){
      if (names(VI3)[i]=="X1"){
        vi_both3[k,m,1]<-VI3[i]
      }
      if (names(VI3)[i]=="X2"){
        vi_both3[k,m,2]<-VI3[i]
      }
      if (names(VI3)[i]=="X3"){
        vi_both3[k,m,3]<-VI3[i]
      }
      if (names(VI3)[i]=="X4"){
        vi_both3[k,m,4]<-VI3[i]
      }
      if (names(VI3)[i]=="X5"){
        vi_both3[k,m,3]<-VI3[i]
      }
      if (names(VI3)[i]=="X6"){
        vi_both3[k,m,6]<-VI3[i]
      }
    }
    }
  }
}

apply(vi_both3[1,,],2,sum)
apply(vi_both3[2,,],2,sum)
apply(vi_both3[3,,],2,sum)


ylim_bar<-range(cbind(apply(vi_both3[1,,],2,sum),apply(vi_both3[2,,],2,sum),apply(vi_both3[3,,],2,sum)))

par(mfrow=c(2,2))
for (k in 1:3){
  if (draw_figure==T) png(paste(c("./plots/three_gaussians/3-mixing-prob-imp-"),k,c(".png"),sep=""))
  barplot(apply(vi_both3[k,,],2,sum),names.arg =  c("x1","x2","x3","x4","x5","x6"),ylab="relative importance",main=paste("relative importance in F",k,sep=""),ylim = ylim_bar)
  box()
  if (draw_figure==T) dev.off()
}

if (draw_figure==T)  png("./plots/three_gaussians/3-mixing-prob-imp-total.png")
barplot(c(sum(vi_both3[,,1]),
sum(vi_both3[,,2]),
sum(vi_both3[,,3]),
sum(vi_both3[,,4]),
sum(vi_both3[,,5]),
sum(vi_both3[,,6])),names.arg =  c("x1","x2","x3","x4","x5","x6"),ylab="relative importance",main="relative importance of covariates")
box()
if (draw_figure==T) dev.off()

vimp_both3<-cbind(apply(vi_both3[1,,],1,sum),apply(vi_both3[2,,],1,sum),apply(vi_both3[3,,],1,sum))

if (draw_figure==T) png("./plots/three_gaussians/3-mixing-prob-loss-track.png")
matplot(vimp_both3,type="l",xlab="boosting iterations in the last EB step",ylab="squared loss reduction",col=1:3,lty = 1:3)
legend("topright",c("F1","F2","F3"),col=1:3,lty = 1:3)
if (draw_figure==T) dev.off()
```

# GLMs both

## Iterations

```{r}
X<-dat[,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-80
model<-"glm"
structure<-"both"
trace<-T
patience<-10
time_temp<-proc.time()
model_glm_both3<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace,patience=patience)
(time_glm_both3<-proc.time()-time_temp)

ylim0<-range(model_glm_both3$learn_loss)
if (draw_figure==T) png("./plots/three_gaussians/loss-glm-both3.png")
matplot(cbind(model_glm_both3$learn_loss,model_glm_both3$test_loss), lty = c(1,1) ,col=c('red',"blue"),ylim=ylim0,xlab = "iterations of EM",ylab="neg LL",type="l", main="EM algorithm for linear model of mu and mixing probs")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_glm_both3$learn_loss),lty=2,col="red")
abline(v=which.min(model_glm_both3$test_loss),lty=2,col="blue")
if (draw_figure==T) dev.off()

(glm_learn_loss_both3 <- model_glm_both3$learn_loss[length(model_glm_both3$learn_loss)])
(glm_test_loss_both3 <- model_glm_both3$test_loss[length(model_glm_both3$test_loss)])
bst_test_loss_both3

glm_both3<- 
  model_glm_both3$test$mu1*model_glm_both3$test$p1+
  model_glm_both3$test$mu2*model_glm_both3$test$p2+
  model_glm_both3$test$mu3*model_glm_both3$test$p3
  
dat_test$glm3<-glm_both3
(glm_test_mse_both3<-mean((dat_test$Y-glm_both3)^2))
bst_test_mse_both3

boxplot(model_glm_both3$test[,c("p1","p2","p3")])
boxplot(model_glm_both3$test[,c("mu1","mu2","mu3")])
```

# GLMs mix 

## Iterations

```{r}
X<-dat[,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-80
model<-"glm"
structure<-"p"
trace<-T
patience<-10
time_temp<-proc.time()
model_glm_both3<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace,patience=patience)
(time_glm_mix3<-proc.time()-time_temp)

ylim0<-range(model_glm_both3$learn_loss)
if (draw_figure==T) png("./plots/three_gaussians/loss-glm-mix3.png")
matplot(cbind(model_glm_both3$learn_loss,model_glm_both3$test_loss), lty = c(1,1) ,col=c('red',"blue"),ylim=ylim0,xlab = "iterations of EM",ylab="neg LL",type="l", main="EM algorithm for linear model of mixing probs")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_glm_both3$learn_loss),lty=2,col="red")
abline(v=which.min(model_glm_both3$test_loss),lty=2,col="blue")
if (draw_figure==T) dev.off()

(glm_learn_loss_mix3 <- model_glm_both3$learn_loss[length(model_glm_both3$learn_loss)])
(glm_test_loss_mix3 <- model_glm_both3$test_loss[length(model_glm_both3$test_loss)])
bst_test_loss_mix3

glm_mix3<- 
  model_glm_both3$test$mu1*model_glm_both3$test$p1+
  model_glm_both3$test$mu2*model_glm_both3$test$p2+
  model_glm_both3$test$mu3*model_glm_both3$test$p3
  
dat_test$glm_mix3<-glm_mix3
(glm_test_mse_mix3<-mean((dat_test$Y-dat_test$glm_mix3)^2))
bst_test_mse_mix3

boxplot(model_glm_both3$test[,c("p1","p2","p3")])
boxplot(model_glm_both3$test[,c("mu1","mu2","mu3")])
```

# Single boosting

```{r}
X<-dat[1:8000,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y[1:8000]
Xval<-dat[8001:10000,c("X1","X2","X3","X4","X5","X6")]
Yval<-dat$Y[8001:10000]
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y
M0<-100

param<-list(max_depth=4, eta =0.5, objective="reg:squarederror")
dtrain<-xgb.DMatrix(data=as.matrix(X), label = Y)
dvalid<-xgb.DMatrix(data=as.matrix(Xval), label= Yval)
dtest<-xgb.DMatrix(data=as.matrix(Xtest))
watchlist=list(train=dtrain, eval= dvalid)
mu_bst0 <-xgb.train(param, dtrain, nrounds=100,verbose = 1,watchlist,early_stopping_rounds = 2)

dat_test$bst_mu0<-predict(mu_bst0,newdata = dtest)
dat_test$sigma0<-sqrt(mean((dat_test$Y-dat_test$bst_mu0)^2))
(bst_test_loss_0<--mean(dnorm(dat_test$Y,dat_test$bst_mu0,sd=dat_test$sigma0,log = T)))
(bst_test_mse_0<-mean((dat_test$Y-dat_test$bst_mu0)^2))
bst_test_mse_mix3

xgb.importance(feature_names=var_ind$var_name,mu_bst0)
```

# Single GLM

```{r}
X<-dat[,c("X1","X2","X3","X4","X5","X6")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4","X5","X6")]
Ytest<-dat_test$Y

mu_glm0 <-glm(Y ~ ., data=X)

dat_test$glm_mu0<-predict(mu_glm0, newdata = Xtest)
dat_test$sigma0_glm<-sqrt(mean((dat_test$Y-dat_test$glm_mu0)^2))
(glm_test_loss_0<--mean(dnorm(dat_test$Y,dat_test$glm_mu0,sd=dat_test$sigma0_glm,log = T)))

(glm_test_mse_0<-mean((dat_test$Y-dat_test$glm_mu0)^2))
bst_test_mse_0
```

# Save results

```{r}
cor_pearson<-round(cor(dat_test[,c("true_mu","bst3","bst_mix3","glm3","glm_mix3",
                                   "bst_mu0","glm_mu0")])[1,-1],4)
cor_kendall<-round(cor(dat_test[,c("true_mu","bst3","bst_mix3","glm3","glm_mix3",
                                   "bst_mu0","glm_mu0")],method = "kendall")[1,-1],4)
cor_spearman<-round(cor(dat_test[,c("true_mu","bst3","bst_mix3","glm3","glm_mix3",
                                   "bst_mu0","glm_mu0")], method ="spearman")[1,-1],4)

result_mat <-
  data.frame(
    model = c(
      "BST-0",
      "BST-1",
      "MLR-0",
      "MLR-1",
      "GBDT",
      "LR",
      "Null",
      "True"
    ),
    loss = round(c(
      bst_test_loss_both3,
      bst_test_loss_mix3,
      glm_test_loss_both3,
      glm_test_loss_mix3,
      bst_test_loss_0,
      glm_test_loss_0,
      homo_test_loss3,
      true_test_loss3
    ),4),
    mse = round(c(
      bst_test_mse_both3,
      bst_test_mse_mix3,
      glm_test_mse_both3,
      glm_test_mse_mix3,
      bst_test_mse_0,
      glm_test_mse_0,
      homo_test_mse3,
      true_test_mse
    ),4),
    pearson= c(cor_pearson,NA,1),
    kendall= c(cor_kendall,NA,1),
    spearman= c(cor_spearman,NA,1),
    parallel =round(c(
      bst_time_parallel3,
      bst_mix_time_parallel3,
      rep(NA,6)
    ),0),
    no_parallel =round(c(
      bst_time_no_parallel3,
      bst_mix_time_no_parallel3,
      rep(NA,6)
    ),0)
    )

result_mat
# write.csv(result_mat,"./plots/three_gaussians/result_mat.csv")
```

