---
title: "Gaussian Mixture Boosting"
author: "Jiahong Li"
date: "2021/9/16"
output: html_document
editor_options: 
  chunk_output_type: console
---

# negative log-likelihood

```{r}
rm(list=ls())
source("0_multiclass_bst.R")
source("0_gaussian_bst.R")
```

# Data genaration

```{r data generation}
n = 8000
ntest = 2000
dat<-sim_gaussian(n,seed=2)
dat_test<-sim_gaussian(ntest,seed=3)
names(dat)
boxplot(dat[,c("P1","P2","P3")])
boxplot(dat_test[,c("P1","P2","P3")])
boxplot(dat[,c("Y1","Y2","Y3")])
boxplot(dat_test[,c("Y1","Y2","Y3")])
plot(density(dat$Y,width = 1))
```

# Homogenous model

```{r}
X<-dat[, c("X1","X2","X3","X4")]
Y<-dat$Y
Xtest<-dat_test[, c("X1","X2","X3","X4")]
Ytest<-dat_test$Y
M0<-15
model<-"null"
structure<-"null"
trace<-T
model_homo<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace)

ylim0<-c(2.01,2.81)
#png("../plots/normal/loss-null.png")
plot(model_homo$learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(model_homo$test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_homo$learn_loss),lty=2,col="red")
abline(v=which.min(model_homo$test_loss),lty=2,col="blue")
#dev.off()
which.min(model_homo$test_loss)

(homo_learn_loss <- min(model_homo$learn_loss))
(homo_test_loss <- min(model_homo$test_loss))
(true_test_loss<-neg_ll3(dat_test$Y,dat_test[,c("MU1","MU2","MU3")],dat_test[,c("SG1","SG2","SG3")], dat_test[,c("P1","P2","P3")]))

(eH<-c(mean((dat_test$MU1-model_homo$test$mu1)^2),mean((dat_test$MU2-model_homo$test$mu2)^2),mean((dat_test$MU3-model_homo$test$mu3)^2),mean((dat_test$F1-model_homo$test$plinear1)^2), mean((dat_test$F2-model_homo$test$plinear2)^2), mean((dat_test$F3-model_homo$test$plinear3)^2) ))
# head(model_homo$valid)
```

# GLMs 

## with varying mu

```{r}
X<-dat[,c("X1","X2","X3","X4")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4")]
Ytest<-dat_test$Y
M0<-50
model<-"glm"
structure<-"mu"
trace<-T
model_glm_mu<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest = Ytest, M0=M0, model=model, structure=structure, trace=trace)

#png("../plots/normal/loss-null.png")
plot(model_glm_mu$learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(model_glm_mu$test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_glm_mu$learn_loss),lty=2,col="red")
abline(v=which.min(model_glm_mu$test_loss),lty=2,col="blue")
#dev.off()
which.min(model_glm_mu$test_loss)

(glm_learn_loss_mu <- min(model_glm_mu$learn_loss))
(glm_test_loss_mu <- min(model_glm_mu$test_loss))
homo_test_loss
true_test_loss

(eGLM_mu<-c(mean((dat_test$MU1-model_glm_mu$test$mu1)^2),mean((dat_test$MU2-model_glm_mu$test$mu2)^2),mean((dat_test$MU3-model_glm_mu$test$mu3)^2),mean((dat_test$F1-model_glm_mu$test$plinear1)^2), mean((dat_test$F2-model_glm_mu$test$plinear2)^2), mean((dat_test$F3-model_glm_mu$test$plinear3)^2) ))
eH
```

## with varying p

```{r}
X<-dat[,c("X1","X2","X3","X4")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4")]
Ytest<-dat_test$Y
M0<-50
model<-"glm"
structure<-"p"
trace<-T
model_glm_p<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace)

#png("../plots/normal/loss-null.png")
plot(model_glm_p$learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(model_glm_p$test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_glm_p$learn_loss),lty=2,col="red")
abline(v=which.min(model_glm_p$test_loss),lty=2,col="blue")
#dev.off()
which.min(model_glm_p$valid_loss)

(glm_learn_loss_p <- min(model_glm_p$learn_loss))
(glm_test_loss_p <- min(model_glm_p$test_loss))
glm_test_loss_mu
homo_test_loss
true_test_loss

(eGLM_p<-c(mean((dat_test$MU1-model_glm_p$test$mu1)^2),mean((dat_test$MU2-model_glm_p$test$mu2)^2),mean((dat_test$MU3-model_glm_p$test$mu3)^2),mean((dat_test$F1-model_glm_p$test$plinear1)^2), mean((dat_test$F2-model_glm_p$test$plinear2)^2), mean((dat_test$F3-model_glm_p$test$plinear3)^2) ))
eGLM_mu
eH
```

## with both

```{r}
X<-dat[,c("X1","X2","X3","X4")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4")]
Ytest<-dat_test$Y
M0<-50
model<-"glm"
structure<-"both"
trace<-T
model_glm_both<-EM_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0, model=model, structure=structure, trace=trace)

#png("../plots/normal/loss-null.png")
plot(model_glm_both$learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(model_glm_both$test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(model_glm_both$learn_loss),lty=2,col="red")
abline(v=which.min(model_glm_both$test_loss),lty=2,col="blue")
#dev.off()
which.min(model_glm_both$test_loss)

(glm_learn_loss_both <- min(model_glm_both$learn_loss))
(glm_test_loss_both <- min(model_glm_both$test_loss))
glm_test_loss_mu
glm_test_loss_p
homo_test_loss
true_test_loss

(eGLM_both<-c(mean((dat_test$MU1-model_glm_both$test$mu1)^2),mean((dat_test$MU2-model_glm_both$test$mu2)^2),mean((dat_test$MU3-model_glm_both$test$mu3)^2),mean((dat_test$F1-model_glm_both$test$plinear1)^2), mean((dat_test$F2-model_glm_both$test$plinear2)^2), mean((dat_test$F3-model_glm_both$test$plinear3)^2) ))
eGLM_mu
eGLM_p
eH
```

# Boosting 

## with varying mu

```{r}
X<-dat[,c("X1","X2","X3","X4")]
Y<-dat$Y
Xtest<-dat_test[,c("X1","X2","X3","X4")]
Ytest<-dat_test$Y
M0<-20
structure<-"mu"
trace<-T
model_bst_mu<-EB_gaussian(X=X, Y=Y, Xtest=Xtest, Ytest=Ytest, M0=M0,  structure=structure, trace=trace)
matplot(cbind(model_bst_mu$train_loss,model_bst_mu$valid_loss),type="l",ylim = ylim0)
abline(v=which.min(model_bst_mu$valid_loss),lty=2)
min(model_bst_mu$valid_loss)
```

## with varying p

```{r}
model_bst_p<-EB_gaussian(X=X, Y=Y, Xval=Xval, Yval=Yval, M0=M0,  structure="p", trace=trace)
matplot(cbind(model_bst_p$train_loss,model_bst_p$valid_loss),type="l")
abline(v=which.min(model_bst_p$valid_loss),lty=2)
min(model_bst_p$valid_loss)
#png("../plots/normal/loss-null.png")
plot(learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(learn_loss),lty=2,col="red")
abline(v=which.min(test_loss),lty=2,col="blue")
#dev.off()
which.min(test_loss)

(bst_learn_loss_vmu <- min(learn_loss))
(bst_test_loss_vmu <- min(test_loss))
glm_test_loss_vmu
homo_test_loss
true_test_loss

(eBST_vmu<-c(mean((dat_test$MU1-par_mat_T$mu1)^2),mean((dat_test$MU2-par_mat_T$mu2)^2),mean((dat_test$MU3-par_mat_T$mu3)^2),mean((dat_test$F1-par_mat_T$pl1)^2), mean((dat_test$F2-par_mat_T$pl2)^2), mean((dat_test$F3-par_mat_T$pl3)^2) ))
eGLM_vmu
eH
```

## with varying both

```{r}
model_bst_both<-EB_gaussian(X=X, Y=Y, Xval=Xval, Yval=Yval, M0=M0,  structure="both", trace=trace)
matplot(cbind(model_bst_both$train_loss,model_bst_both$valid_loss),type="l")
abline(v=which.min(model_bst_both$valid_loss),lty=2)
min(model_bst_both$valid_loss)

#png("../plots/normal/loss-null.png")
plot(learn_loss,type = 'l',col='red',ylim=ylim0,xlab = "iterations of EM",ylab="neg LL")
lines(test_loss,type="l",col="blue")
legend("topright",c("learn loss","test loss"),col=c("red","blue"),lty=c(1,1))
abline(v=which.min(learn_loss),lty=2,col="red")
abline(v=which.min(test_loss),lty=2,col="blue")
#dev.off()
which.min(test_loss)

(bst_learn_loss_vmu <- min(learn_loss))
(bst_test_loss_vmu <- min(test_loss))
glm_test_loss_vmu
homo_test_loss
true_test_loss

(eBST_vmu<-c(mean((dat_test$MU1-par_mat_T$mu1)^2),mean((dat_test$MU2-par_mat_T$mu2)^2),mean((dat_test$MU3-par_mat_T$mu3)^2),mean((dat_test$F1-par_mat_T$pl1)^2), mean((dat_test$F2-par_mat_T$pl2)^2), mean((dat_test$F3-par_mat_T$pl3)^2) ))
eGLM_vmu
eH
```

```{r}
loss_mat<-data.frame(model=c("homo","glm_cp","glm_vp","boosting_cp","boosting_vp"),negL=c(homo_test_loss,glm_test_loss_cp,glm_test_loss_vp,boost_loss_cp,boost_loss_vp),mu1_error=NA,mu2_error=NA,plinear_error=NA)

loss_mat[,3:5]<-rbind(eH,eGLM_cp,eGLM_vp,eBST_cp,eBST_vp)
loss_mat
# write.csv(loss_mat,"../plots/gaussian_loss_mat.csv")
```

