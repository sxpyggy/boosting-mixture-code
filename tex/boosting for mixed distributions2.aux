\relax 
\citation{goldfeld1973markov}
\citation{lindsay1995mixture}
\citation{peel2000finite}
\citation{jacobs1991adaptive,jiang1999hierarchical}
\citation{zhang2020type,zhang2022new}
\citation{delong2021gamma}
\citation{lee2010modeling}
\citation{verbelen2015fitting}
\citation{lee2012modeling}
\citation{fung2019class2}
\citation{fung2019class}
\citation{tseung2021lrmoe}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\citation{dempster1977maximum}
\citation{khalili2007variable}
\citation{huang2012mixture}
\citation{huang2013nonparametric}
\citation{naik2007extending}
\citation{kasahara2015testing}
\citation{friedman2001greedy}
\citation{buehlmann:2003}
\citation{peel2000finite}
\@writefile{toc}{\contentsline {section}{\numberline {2}Review: mixture models and the EM algorithm}{3}{}\protected@file@percent }
\newlabel{sec:review}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Mixture models}{3}{}\protected@file@percent }
\newlabel{review:mix1}{{2.1}{3}}
\newlabel{mix-gen}{{2.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The EM algorithm}{4}{}\protected@file@percent }
\newlabel{full-L}{{2.2}{4}}
\newlabel{p-reg}{{2.3}{4}}
\newlabel{comp-reg}{{2.4}{5}}
\@writefile{toc}{\contentsline {paragraph}{Expectation step.}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Maximization step.}{5}{}\protected@file@percent }
\newlabel{likelihood}{{2.5}{5}}
\newlabel{p-reg2}{{2.6}{5}}
\newlabel{comp-reg2}{{2.7}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Expectation-Boosting algorithm}{5}{}\protected@file@percent }
\newlabel{sec:EB}{{3}{5}}
\citation{buehlmann:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generic functional gradient descent algorithm}{6}{}\protected@file@percent }
\newlabel{logit-link}{{3.1}{6}}
\newlabel{l2}{{3.2}{6}}
\citation{breiman1983classification}
\citation{hastie2009elements}
\citation{buhlmann2007boosting}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces The generic functional gradient decent algorithm.}}{7}{}\protected@file@percent }
\newlabel{alg1}{{1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Expectation-Boosting algorithm}{7}{}\protected@file@percent }
\newlabel{inv-logistic}{{3.3}{8}}
\newlabel{logistic}{{3.4}{8}}
\newlabel{p-loss}{{3.5}{8}}
\newlabel{p-gradient}{{3.6}{8}}
\newlabel{comp-loss}{{3.7}{8}}
\newlabel{comp-gradient}{{3.8}{8}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces The Expectation-Boosting algorithm.}}{9}{}\protected@file@percent }
\newlabel{EB}{{2}{9}}
\citation{jorgensen:1997}
\newlabel{ini-1}{{3.9}{10}}
\citation{friedman2001greedy}
\newlabel{ini-2}{{3.10}{11}}
\citation{friedman2001greedy}
\citation{breiman1983classification}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Interpretation, hyperparameters tuning and initialization in the EB algorithm}{13}{}\protected@file@percent }
\newlabel{influence}{{3.12}{13}}
\citation{hastie2009elements}
\newlabel{loss-p}{{3.15}{14}}
\newlabel{loss-mu}{{3.16}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Applications}{15}{}\protected@file@percent }
\newlabel{sec:application}{{4}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}First simulated example: zero-inflated Poisson model}{15}{}\protected@file@percent }
\newlabel{zip-test-loss}{{4.4}{16}}
\newlabel{t1}{{4.5}{16}}
\newlabel{t2}{{4.6}{16}}
\newlabel{zip-null}{{4.7}{16}}
\newlabel{zip-cp}{{4.9}{16}}
\newlabel{zip-cl}{{4.10}{16}}
\newlabel{zip-v}{{4.11}{16}}
\newlabel{zip-bst-cp}{{4.12}{17}}
\newlabel{zip-bst-cl}{{4.13}{17}}
\newlabel{zip-bst-v}{{4.14}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of different ZIP models on the test data. Note that Models \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.7\hbox {}\unskip \@@italiccorr )}}, \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.9\hbox {}\unskip \@@italiccorr )}}, \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.10\hbox {}\unskip \@@italiccorr )}} and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.11\hbox {}\unskip \@@italiccorr )}} are estimated via the EM algorithm, while Models \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.12\hbox {}\unskip \@@italiccorr )}}, \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.13\hbox {}\unskip \@@italiccorr )}} and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.14\hbox {}\unskip \@@italiccorr )}} are estimated via the EB algorithm.}}{17}{}\protected@file@percent }
\newlabel{zip}{{1}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Second simulated example: mixture of Gaussians}{18}{}\protected@file@percent }
\newlabel{logistic-ex}{{4.16}{18}}
\newlabel{gaussian-0}{{4.17}{18}}
\newlabel{gaussian-glm-mu}{{4.18}{18}}
\newlabel{linear-mu}{{4.19}{18}}
\newlabel{gaussian-glm-p}{{4.20}{18}}
\newlabel{linear-p}{{4.21}{19}}
\newlabel{linear-p2}{{4.22}{19}}
\newlabel{gaussian-glm-b}{{4.23}{19}}
\newlabel{gaussian-bst-mu}{{4.24}{19}}
\newlabel{gaussian-bst-p}{{4.25}{19}}
\newlabel{bst-p}{{4.26}{19}}
\newlabel{gaussian-bst-b}{{4.27}{19}}
\citation{embrechts2013modelling}
\citation{resnick1997heavy}
\citation{wuthrich2022statistical}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of different models in terms of test loss and running time.{\color  {blue}[Not easy to distinguish the results between EM and EB]}}}{20}{}\protected@file@percent }
\newlabel{gaussian-summary}{{2}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Third example: claims severity modelling}{20}{}\protected@file@percent }
\newlabel{sec:third example}{{4.3}{20}}
\newlabel{sev-0}{{4.28}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histogram and the cumulative distribution function of logged average claims.}}{21}{}\protected@file@percent }
\newlabel{hist}{{1}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The logged survival function and the Hill plot for logged average claims.}}{21}{}\protected@file@percent }
\newlabel{tail}{{2}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The trace plot the learning loss for the homogeneous model \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.28\hbox {}\unskip \@@italiccorr )}} during the EM iterations.}}{22}{}\protected@file@percent }
\newlabel{null_sev}{{3}{22}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The MLEs of component parameters in the homogeneous model \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.28\hbox {}\unskip \@@italiccorr )}}. Tail index is estimated as $\hat  {\alpha }=1.0773$.}}{22}{}\protected@file@percent }
\newlabel{null-gamma}{{3}{22}}
\newlabel{sev-bst-p}{{4.30}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The boxplot of the estimated mixing probabilities in Model \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 4.30\hbox {}\unskip \@@italiccorr )}}.}}{23}{}\protected@file@percent }
\newlabel{bx-bst-p}{{4}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{23}{}\protected@file@percent }
\newlabel{sec:conclusions}{{5}{23}}
\bibdata{boosting}
\bibcite{breiman1983classification}{{1}{1984}{{Breiman et~al.}}{{Breiman, H, Olshen and\ Stone}}}
\bibcite{buhlmann2007boosting}{{2}{2007}{{B{\"u}hlmann and\ Hothorn}}{{}}}
\bibcite{buehlmann:2003}{{3}{2003}{{B{\"u}hlmann and\ Yu}}{{}}}
\bibcite{delong2021gamma}{{4}{2021}{{Delong et~al.}}{{Delong, Lindholm and\ W{\"u}thrich}}}
\bibcite{dempster1977maximum}{{5}{1977}{{Dempster et~al.}}{{Dempster, Laird and\ Rubin}}}
\bibcite{embrechts2013modelling}{{6}{1997}{{Embrechts et~al.}}{{Embrechts, Kl{\"u}ppelberg and\ Mikosch}}}
\bibcite{friedman2001greedy}{{7}{2001}{{Friedman}}{{}}}
\bibcite{fung2019class2}{{8}{2019a}{{Fung et~al.}}{{Fung, Badescu and\ Lin}}}
\bibcite{fung2019class}{{9}{2019b}{{Fung et~al.}}{{Fung, Badescu and\ Lin}}}
\bibcite{goldfeld1973markov}{{10}{1973}{{Goldfeld and\ Quandt}}{{}}}
\bibcite{hastie2009elements}{{11}{2009}{{Hastie et~al.}}{{Hastie, Tibshirani and\ Friedman}}}
\bibcite{huang2013nonparametric}{{12}{2013}{{Huang et~al.}}{{Huang, Li and\ Wang}}}
\bibcite{huang2012mixture}{{13}{2012}{{Huang and\ Yao}}{{}}}
\bibcite{jacobs1991adaptive}{{14}{1991}{{Jacobs et~al.}}{{Jacobs, Jordan, Nowlan and\ Hinton}}}
\bibcite{jiang1999hierarchical}{{15}{1999}{{Jiang and\ Tanner}}{{}}}
\bibcite{jorgensen:1997}{{16}{1997}{{Jorgensen}}{{}}}
\bibcite{kasahara2015testing}{{17}{2015}{{Kasahara and\ Shimotsu}}{{}}}
\bibcite{khalili2007variable}{{18}{2007}{{Khalili and\ Chen}}{{}}}
\bibcite{lee2010modeling}{{19}{2010}{{Lee and\ Lin}}{{}}}
\bibcite{lee2012modeling}{{20}{2012}{{Lee and\ Lin}}{{}}}
\bibcite{lindsay1995mixture}{{21}{1995}{{Lindsay}}{{}}}
\bibcite{peel2000finite}{{22}{2000}{{MacLahlan and\ Peel}}{{}}}
\bibcite{naik2007extending}{{23}{2007}{{Naik et~al.}}{{Naik, Shi and\ Tsai}}}
\bibcite{resnick1997heavy}{{24}{1997}{{Resnick}}{{}}}
\bibcite{tseung2021lrmoe}{{25}{2021}{{Tseung et~al.}}{{Tseung, Badescu, Fung and\ Lin}}}
\bibcite{verbelen2015fitting}{{26}{2015}{{Verbelen et~al.}}{{Verbelen, Gong, Antonio, Badescu and\ Lin}}}
\bibcite{wuthrich2022statistical}{{27}{2022}{{W\"uthrich and\ Merz}}{{}}}
\bibcite{zhang2020type}{{28}{2020}{{Zhang et~al.}}{{Zhang, Calderin, Li and\ Wu}}}
\bibcite{zhang2022new}{{29}{2022}{{Zhang et~al.}}{{Zhang, Pitt and\ Wu}}}
\bibstyle{boosting}
\gdef \@abspage@last{25}
